  <div class="container mx-auto px-4 py-8">
    <%= render 'home/header' %>
    
    <!-- Benchmarks Page -->
    <div id="benchmarks-page" class="page active-page">
      <div class="dashboard-header">
        <div class="title-area">
          <h1 id="dataset-title">MedQA Performance Evaluation</h1>
          <div class="subtitle">Comparative analysis of large language models on medical question answering tasks</div>
        </div>
        <div class="filters">
          <button class="filter-button" id="filter-button" style="display: none;">Filter by Subject <span class="sort-icon">◉</span></button>
        </div>
      </div>
      
      <div class="dataset-selector" style="display: flex; flex-wrap: nowrap; overflow-x: auto; gap: 10px; padding: 10px 0; -webkit-overflow-scrolling: touch;">
        <button class="dataset-button active" id="medqa-button" style="flex: 0 0 auto; white-space: nowrap;">MedQA</button>
        <button class="dataset-button" id="medmcqa-button" style="flex: 0 0 auto; white-space: nowrap;">MedMCQA</button>
        <button class="dataset-button" id="clinical-notes-button" style="flex: 0 0 auto; white-space: nowrap;">Clinical Notes <span class="coming-soon">Coming soon</span></button>
        <button class="dataset-button" id="diagnosis-button" style="flex: 0 0 auto; white-space: nowrap;">Diagnosis <span class="coming-soon">Coming soon</span></button>
        <button class="dataset-button" id="bedside-manner-button" style="flex: 0 0 auto; white-space: nowrap;">Bedside Manner <span class="coming-soon">Coming soon</span></button>
      </div>
      
      <div class="tabs">
        <div class="tab active" id="performance-tab">Performance</div>
      </div>
      
      <div class="tables-container">
        <table class="results-table" id="medqa-data">
          <thead>
            <tr>
              <th class="rank">#</th>
              <th>Model</th>
              <th class="sort-header">
                <button class="sort-button desc" data-column="accuracy">
                  Accuracy <span class="sort-icon">▼</span>
                </button>
              </th>
              <th>Accuracy - 95% CI</th>
              <th class="sort-header">
                <button class="sort-button" data-column="input-cost">
                  Input Cost (/1M tokens) <span class="sort-icon">◆</span>
                </button>
              </th>
              <th class="sort-header">
                <button class="sort-button" data-column="output-cost">
                  Output Cost (/1M tokens) <span class="sort-icon">◆</span>
                </button>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="rank">1</td>
              <td class="model-name">
                <div class="model-icon top-performer">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/4/4d/OpenAI_Logo.svg" alt="OpenAI">
                </div>
                OpenAI o3-mini
              </td>
              <td class="accuracy">95.19%</td>
              <td class="confidence-interval">94.76% - 95.59%</td>
              <td class="cost">$1.1</td>
              <td class="cost">$4.4</td>
            </tr>
            <tr>
              <td class="rank">2</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/e/ec/DeepSeek_logo.svg" alt="DeepSeek">
                </div>
                DeepSeek-R1
              </td>
              <td class="accuracy">91.91%</td>
              <td class="confidence-interval">91.36% - 92.42%</td>
              <td class="cost">$0.55</td>
              <td class="cost">$2.19</td>
            </tr>
            <tr>
              <td class="rank">3</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/7/7b/Meta_Platforms_Inc._logo.svg" alt="Meta">
                </div>
                Llama 3.3 70B Instruct
              </td>
              <td class="accuracy">90.88%</td>
              <td class="confidence-interval">90.31% - 91.42%</td>
              <td class="cost">$0.12</td>
              <td class="cost">$0.3</td>
            </tr>
            <tr>
              <td class="rank">4</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/7/78/Anthropic_logo.svg" alt="Anthropic">
                </div>
                Claude 3.7 Sonnet
              </td>
              <td class="accuracy">87.88%</td>
              <td class="confidence-interval">87.23% - 88.5%</td>
              <td class="cost">$3</td>
              <td class="cost">$15</td>
            </tr>
            <tr>
              <td class="rank">5</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/8/8a/Google_Gemini_logo.svg" alt="Google">
                </div>
                Gemini Flash 2.0
              </td>
              <td class="accuracy">82.7%</td>
              <td class="confidence-interval">81.95% - 83.42%</td>
              <td class="cost">$0.1</td>
              <td class="cost">$0.4</td>
            </tr>
            <tr>
              <td class="rank">6</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/8/8a/Google_Gemini_logo.svg" alt="Google">
                </div>
                Gemini 2.0 Flash Lite
              </td>
              <td class="accuracy">77.18%</td>
              <td class="confidence-interval">76.36% - 77.99%</td>
              <td class="cost">$0.075</td>
              <td class="cost">$0.3</td>
            </tr>
            <tr>
              <td class="rank">7</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/e/e6/Mistral_AI_logo_%282025%E2%80%93%29.svg" alt="Mistral AI">
                </div>
                Mistral Large 2411
              </td>
              <td class="accuracy">74.23%</td>
              <td class="confidence-interval">73.37% - 75.07%</td>
              <td class="cost">$2</td>
              <td class="cost">$6</td>
            </tr>
            <tr>
              <td class="rank">8</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/4/4d/OpenAI_Logo.svg" alt="OpenAI">
                </div>
                OpenAI GPT-4o-mini
              </td>
              <td class="accuracy">73.99%</td>
              <td class="confidence-interval">73.13% - 74.84%</td>
              <td class="cost">$0.15</td>
              <td class="cost">$0.6</td>
            </tr>
            <tr>
              <td class="rank">9</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/e/e6/Mistral_AI_logo_%282025%E2%80%93%29.svg" alt="Mistral AI">
                </div>
                Mistral Small 3.1 24B
              </td>
              <td class="accuracy">68.77%</td>
              <td class="confidence-interval">67.86% - 69.67%</td>
              <td class="cost">$0.1</td>
              <td class="cost">$0.3</td>
            </tr>
            <tr>
              <td class="rank">10</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/4/43/Qwen_2.5.jpg" alt="Qwen">
                </div>
                Qwen2.5 32B Instruct
              </td>
              <td class="accuracy">68.77%</td>
              <td class="confidence-interval">67.86% - 69.66%</td>
              <td class="cost">$0.79</td>
              <td class="cost">$0.79</td>
            </tr>
            <tr>
              <td class="rank">11</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/2/2f/Google_2015_logo.svg" alt="Google">
                </div>
                Gemma 3 - 27b
              </td>
              <td class="accuracy">67.44%</td>
              <td class="confidence-interval">66.53% - 68.35%</td>
              <td class="cost">$0.1</td>
              <td class="cost">$0.2</td>
            </tr>
            <tr>
              <td class="rank">12</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/7/7b/Meta_Platforms_Inc._logo.svg" alt="Meta">
                </div>
                Llama 3.2 3B Instruct
              </td>
              <td class="accuracy">67.29%</td>
              <td class="confidence-interval">66.37% - 68.2%</td>
              <td class="cost">$0.015</td>
              <td class="cost">$0.025</td>
            </tr>
            <tr>
              <td class="rank">13</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/8/8a/Google_Gemini_logo.svg" alt="Google">
                </div>
                Gemini Flash 1.5 8B
              </td>
              <td class="accuracy">59.59%</td>
              <td class="confidence-interval">58.63% - 60.54%</td>
              <td class="cost">$0.0375</td>
              <td class="cost">$0.15</td>
            </tr>

          </tbody>
        </table>
        
        <table class="results-table" id="medmcqa-data" style="display: none;">
          <thead>
            <tr>
              <th class="rank">#</th>
              <th>Model</th>
              <th class="sort-header">
                <button class="sort-button desc" data-column="accuracy">
                  Accuracy <span class="sort-icon">▼</span>
                </button>
              </th>
              <th>Accuracy - 95% CI</th>
              <th class="sort-header">
                <button class="sort-button" data-column="input-cost">
                  Input Cost (/1M tokens) <span class="sort-icon">◆</span>
                </button>
              </th>
              <th class="sort-header">
                <button class="sort-button" data-column="output-cost">
                  Output Cost (/1M tokens) <span class="sort-icon">◆</span>
                </button>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="rank">1</td>
              <td class="model-name">
                <div class="model-icon top-performer">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/7/7b/Meta_Platforms_Inc._logo.svg" alt="Meta">
                </div>
                Llama 3.3 70B Instruct
              </td>
              <td class="accuracy">91.83%</td>
              <td class="confidence-interval">91.67% - 91.98%</td>
              <td class="cost">$0.12</td>
              <td class="cost">$0.3</td>
            </tr>
            <tr>
              <td class="rank">2</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/e/ec/DeepSeek_logo.svg" alt="DeepSeek">
                </div>
                DeepSeek-R1
              </td>
              <td class="accuracy">87.96%</td>
              <td class="confidence-interval">87.77% - 88.14%</td>
              <td class="cost">$0.55</td>
              <td class="cost">$2.19</td>
            </tr>
            <tr>
              <td class="rank">3</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/7/78/Anthropic_logo.svg" alt="Anthropic">
                </div>
                Claude 3.7 Sonnet
              </td>
              <td class="accuracy">86.15%</td>
              <td class="confidence-interval">85.96% - 86.35%</td>
              <td class="cost">$3</td>
              <td class="cost">$15</td>
            </tr>
            <tr>
              <td class="rank">4</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/4/4d/OpenAI_Logo.svg" alt="OpenAI">
                </div>
                OpenAI o3-mini
              </td>
              <td class="accuracy">85.64%</td>
              <td class="confidence-interval">85.01% - 86.25%</td>
              <td class="cost">$1.1</td>
              <td class="cost">$4.4</td>
            </tr>
            <tr>
              <td class="rank">5</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/8/8a/Google_Gemini_logo.svg" alt="Google">
                </div>
                Gemini Flash 2.0
              </td>
              <td class="accuracy">83.28%</td>
              <td class="confidence-interval">83.07% - 83.49%</td>
              <td class="cost">$0.1</td>
              <td class="cost">$0.4</td>
            </tr>
            <tr>
              <td class="rank">6</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/8/8a/Google_Gemini_logo.svg" alt="Google">
                </div>
                Gemini 2.0 Flash Lite
              </td>
              <td class="accuracy">79.63%</td>
              <td class="confidence-interval">79.4% - 79.85%</td>
              <td class="cost">$0.075</td>
              <td class="cost">$0.3</td>
            </tr>
            <tr>
              <td class="rank">7</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/e/e6/Mistral_AI_logo_%282025%E2%80%93%29.svg" alt="Mistral AI">
                </div>
                Mistral Large 2411
              </td>
              <td class="accuracy">76.01%</td>
              <td class="confidence-interval">75.75% - 76.27%</td>
              <td class="cost">$2</td>
              <td class="cost">$6</td>
            </tr>
            <tr>
              <td class="rank">8</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/4/4d/OpenAI_Logo.svg" alt="OpenAI">
                </div>
                OpenAI GPT-4o-mini
              </td>
              <td class="accuracy">75.22%</td>
              <td class="confidence-interval">74.97% - 75.46%</td>
              <td class="cost">$0.15</td>
              <td class="cost">$0.6</td>
            </tr>
            <tr>
              <td class="rank">9</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/4/43/Qwen_2.5.jpg" alt="Qwen">
                </div>
                Qwen2.5 32B Instruct
              </td>
              <td class="accuracy">73.11%</td>
              <td class="confidence-interval">72.86% - 73.36%</td>
              <td class="cost">$0.79</td>
              <td class="cost">$0.79</td>
            </tr>
            <tr>
              <td class="rank">10</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/7/7b/Meta_Platforms_Inc._logo.svg" alt="Meta">
                </div>
                Llama 3.2 3B Instruct
              </td>
              <td class="accuracy">72.05%</td>
              <td class="confidence-interval">71.8% - 72.31%</td>
              <td class="cost">$0.015</td>
              <td class="cost">$0.025</td>
            </tr>
            <tr>
              <td class="rank">11</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/e/e6/Mistral_AI_logo_%282025%E2%80%93%29.svg" alt="Mistral AI">
                </div>
                Mistral Small 3.1 24B
              </td>
              <td class="accuracy">71.75%</td>
              <td class="confidence-interval">71.49% - 72.0%</td>
              <td class="cost">$0.1</td>
              <td class="cost">$0.3</td>
            </tr>
            <tr>
              <td class="rank">12</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/2/2f/Google_2015_logo.svg" alt="Google">
                </div>
                Gemma 3 27B
              </td>
              <td class="accuracy">70.14%</td>
              <td class="confidence-interval">69.88% - 70.4%</td>
              <td class="cost">$0.1</td>
              <td class="cost">$0.2</td>
            </tr>
            <tr>
              <td class="rank">13</td>
              <td class="model-name">
                <div class="model-icon">
                  <img src="https://upload.wikimedia.org/wikipedia/commons/8/8a/Google_Gemini_logo.svg" alt="Google">
                </div>
                Gemini Flash 1.5 8B
              </td>
              <td class="accuracy">64.56%</td>
              <td class="confidence-interval">64.29% - 64.83%</td>
              <td class="cost">$0.0375</td>
              <td class="cost">$0.15</td>
            </tr>
          </tbody>
        </table>

        <div id="coming-soon-message" class="coming-soon-container" style="display: none;">
          <div class="coming-soon-message">Benchmarking data is coming soon!</div>
        </div>
      </div>
      
      <div class="updated-date">
        Last updated: March 25, 2025
      </div>
      
    </div>

    
    <!-- Methodology Page -->
<div id="methodology-page" class="page">
  <div class="dashboard-header">
    <div class="title-area">
      <h1>Benchmark Methodology</h1>
      <div class="subtitle">How we evaluate language models on medical tasks</div>
    </div>
  </div>
  
  <div style="display: flex; gap: 20px; margin-top: 0;">
    <div class="key-insights" style="flex: 1; margin-top: 0;">
      <h2>Evaluation Framework</h2>
      <p style="margin-bottom: 20px;">Our benchmarking methodology follows a rigorous protocol designed to assess LLMs on their medical knowledge, reasoning, and clinical relevance.</p>
      
      <h3 style="margin-bottom: 10px; font-size: 18px;">Key Principles</h3>
      <ul class="insights-list">
        <li><strong>Standardized Prompting:</strong> We use identical prompts across all models to ensure fair and consistent comparisons.</li>
        <li><strong>Default Model Configurations:</strong> All models are run with their default configuration.</li>
        <li><strong>Objective Evaluation:</strong> We measure performance against standardized evaluation datasets to provide quantifiable and reproducible results.</li>
        <li><strong>Transparency and Collaboration:</strong> Our methods are open-source to encourage collaboration and community contributions.</li>
      </ul>
      
      <h3 style="margin-bottom: 10px; margin-top: 20px; font-size: 18px;">Standard Prompt Template</h3>
      <div class="code-container" style="background-color: #f5f5f5; border-radius: 6px; padding: 15px; margin-bottom: 20px; overflow: auto; border: 1px solid #e0e0e0;">
        <pre style="margin: 0; white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 14px;"><code>You are a medical assistant. Please answer the following multiple choice question.

Question: {question}

Options:
{options}

## Output Format:
Please provide your answer in JSON format that contains an "answer" field.

Example response format:
{"answer": "X. exact option text here"}

Important:
- Please ensure that your answer is in valid JSON format.</code></pre>
      </div>
    </div>

    <!-- Right Column - Example with MedMCQA Question -->
    <div class="key-insights" style="flex: 1; margin-top: 0;">
      <h2>Example Prompt</h2>
      <p style="margin-bottom: 20px;">Question extracted from the MedMCQA dataset</p>
      
      <h3 style="margin-bottom: 10px; font-size: 18px;">Sample Question Prompt</h3>
      <div class="code-container" style="background-color: #f5f5f5; border-radius: 6px; padding: 15px; margin-bottom: 20px; overflow: auto; border: 1px solid #e0e0e0;">
        <pre style="margin: 0; white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 14px;"><code>You are a medical assistant. Please answer the following multiple choice question.

Question:
Which one of the following specimen is not refrigerated prior to inoculation?

Options:
A. CSF
B. Plus
C. Urine 
D. Sputum

## Output Format:
Please provide your answer in JSON format that contains an "answer" field.

Example response format:
{"answer": "X. exact option text here"}

Important:
- Please ensure that your answer is in valid JSON format.</code></pre>
      </div>
      
      <h3 style="margin-bottom: 10px; font-size: 18px;">Model Response Example</h3>
      <div style="background-color: #f0f8ff; border-radius: 6px; padding: 15px; margin-bottom: 20px; overflow: auto; border: 1px solid #d0e0f0;">
        <pre style="margin: 0; white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 14px;"><code>{"answer": "A. CSF"}</code></pre>
      </div>
      
      <div style="background-color: #f9f9f9; border: 1px solid #e0e0e0; border-radius: 6px; padding: 15px;">
        <h4 style="margin-top: 0; margin-bottom: 10px; font-size: 16px;">Evaluation Details</h4>
        <ul style="padding-left: 20px; margin-bottom: 10px;">
          <li><strong>Correct Answer:</strong> A. CSF</li>
          <li><strong>Subject:</strong> Microbiology</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<!-- Datasets Page -->
<div id="datasets-page" class="page">
  <div class="dashboard-header">
    <div class="title-area">
      <h1>Benchmark Datasets</h1>
      <div class="subtitle">Information about our evaluation datasets</div>
    </div>
  </div>
  
  <div class="key-insights" style="margin-top: 0;">
    <h2>MedQA <a href="https://arxiv.org/pdf/2009.13081" target="_blank" style="font-size: 14px; margin-left: 10px; text-decoration: none; color: var(--primary);">[Paper]</a> <a href="https://github.com/jind11/MedQA" target="_blank" style="font-size: 14px; margin-left: 5px; text-decoration: none; color: var(--primary);">[GitHub]</a></h2>
    <p style="margin-bottom: 20px;">Multiple choice question answering based on the United States Medical License Exams (USMLE).</p>
    
    <ul class="insights-list">
      <li><strong>Size:</strong> 12,723 questions (English version)</li>
      <li><strong>Benchmark Set:</strong> We evaluate the models against the 10,178 questions in the train split of the data</li>
      <li><strong>Format:</strong> Multiple choice questions</li>
      <li><strong>Citation:</strong> <span style="font-family: monospace; font-size: 0.9em; background-color: #f8f9fa; padding: 10px; display: block; margin-top: 10px; border-left: 3px solid var(--primary); overflow-x: auto;">Pal, A., Umapathi, L.K. and Sankarasubbu, M., 2022, April. Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering. In *Conference on health, inference, and learning* (pp. 248-260). PMLR.</span></li>
  </ul>
  </div>
  
  <div class="key-insights">
    <h2>MedMCQA <a href="https://arxiv.org/pdf/2203.14371" target="_blank" style="font-size: 14px; margin-left: 10px; text-decoration: none; color: var(--primary);">[Paper]</a> <a href="https://github.com/medmcqa" target="_blank" style="font-size: 14px; margin-left: 5px; text-decoration: none; color: var(--primary);">[GitHub]</a></h2>
    <p style="margin-bottom: 20px;">A large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.</p>
    
    <ul class="insights-list">
      <li><strong>Size:</strong> 194,000+ questions</li>
      <li><strong>Benchmark Set:</strong> We evaluate the models against the 120,765 single-select questions in the train split of the data</li>
      <li><strong>Format:</strong> Multiple choice questions</li>
      <li><strong>Coverage:</strong> Twenty-one medical subjects including anatomy, physiology, biochemistry, pathology, and pharmacology</li>
      <li><strong>Citation:</strong> <span style="font-family: monospace; font-size: 0.9em; background-color: #f8f9fa; padding: 10px; display: block; margin-top: 10px; border-left: 3px solid var(--primary); overflow-x: auto;">Pal, A., Umapathi, L.K. and Sankarasubbu, M., 2022, April. Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering. In *Conference on health, inference, and learning* (pp. 248-260). PMLR.</span></li>
    </ul>
  </div>
  
</div>
</div>

